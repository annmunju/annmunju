# Dataflow 사용한 서버리스 데이터 처리

## Dataflow 소개
- Dataproc과 다르게 Dataflow의 자동 확장이 세밀하게 단계별로 진행됨
    - 하둡과 스파크 종속적인 경우 Dataproc을 사용하는 것이 더 좋음 / 새로운 파이프라인 구축을 위해서는 Dataflow 사용이 좋음
    - 머신 프로비저닝이 필요할 때는 Dataproc을 사용 / 서버리스로 사용하려면 Dataflow 사용이 용이
- 배치와 스트림 모두 같은 코드를 사용할 수 있음
    - Beam 특성은 기존 배치 프로그래밍 개념 + 데이터 처리 개념을 통합하는 추상화 제공
- 구성 요소
    - Pipeline: 데이터 처리 작업의 설계도
    - PCollection: 파이프라인 안에서 처리되는 불변 데이터 묶음
    - PTransform: 데이터를 변환하는 함수/연산 단위
    - Runner: 파이프라인을 실제 환경(로컬/클라우드)에서 실행하는 엔진

## Dataflow 선택 이유(강점)
- 항상 최적화 진행중. 완전 관리형이며 자동 구성됨
- 예약된 작업 보장. 내결함성 제공
- Beam 변환을 그대로 실행하는 것이 아닌, 연산 통합 후 그래프 최적화.
- 늦게 도착하는 레코드 처리 가능. 
- GCP 서비스를 하나로 묶는 접착제 역할을 할 수 있음

## Dataflow pipeline
- 소스(Source): 입력 데이터 읽기 (ReadFromText, ReadFromBigQuery 등)
- 변환(Transforms): PTransform(FlatMap, Filter, GroupByKey 등)을 | 연산자로 연결
- 분기(Branch): 같은 PCollection을 여러 변환에 전달 → 결과 각각 변수로 저장
- 싱크(Sink): 최종 PCollection을 저장 (WriteToText, WriteToBigQuery 등)
- 실행(Runner): 로컬(개발용) 또는 Dataflow(클라우드 확장 실행)에서 실행

- 파이프라인 설계시 주요 고려사항
    - 입력(Source)
        - ReadFromText → GCS 파일 읽기
        - ReadFromPubSub → 실시간 메시지
        - ReadFromBigQuery → 테이블/쿼리 결과
    - 출력(Sink)
        - WriteToBigQuery → 테이블에 저장 (옵션에 따라 append/truncate 가능)
        - WriteToText → GCS 텍스트 파일에 저장 등
    - 메모리에서 직접 생성
        - beam.Create([...]) → 작은 상수 데이터 세트

## PTransform

## GroupByKey

## 