### Data Engineering Tasks and Components

데이터 엔지니어 역할
- 데이터 파이프라인 빌드
- 원시 데이터 → 유용한 상태의 데이터로 변환 
- 데이터 사용량을 프로덕션 설정으로 옮기기 위한 프로세스 진행
- Replicate and migrate → Ingest → Transform → Store

데이터 소스와 데이터 싱크의 차이
- Ingest : 데이터 소스 → 데이터 레이크 (원시 데이터, 애플리케이션에서 수집된 모든 데이터) 
- Transform : Extract and load, Extract-load-transform, Extract-transform-load
- Store : 데이터 싱크. 데이터의 종착지로 대표적으로 bigquery, bigtable가 있음

데이터 형식
- 비정형과 정형 (빅쿼리에서도 비정형 저장 가능)

데이터 저장 옵션
- cloud storage : 객체 access 시 http로 통 객체 이름을 키로 함. 객체에 메타데이터가 있지만 객체 자체는 비정형 바이트로 취급.
    - Standard (hot) < Nearline (1month) < Coldline (90days) < Archive (1year)

메타데이터 관리
- dataplex : unified metadata, auto-discovery, data lifecycle, data quality, data classification, data organization, unified security, unified governance
- Analytics Hub로 데이터 세트 공유
- BigQuery의 **데이터 공유 기능을 확장**한 플랫폼
- 기업/기관/팀 간에 **데이터 세트를 안전하게 공유**하거나 **퍼블릭하게 배포** 가능
- GCP 내외의 조직 간 **중복 저장 없이 공유**할 수 있음
- 데이터 소비자는 **자신의 BigQuery 프로젝트에서 쿼리만 실행**

---

### Data Replication and Migration

데이터 복제와 마이그레이션 아키텍처
- 스토리지 트렌스퍼 서비스, 스토리지 트렌스퍼 어플리케이션, 데이터 스트림 사용

명령줄도구 옵션과 사용 사례
- gcloud storage cp  *.csv …

스토리지 트렌스퍼 서비스 기능 사용사례 
- 비교적 큰 데이터 세트 이동. 대규모 데이터 세트를 cloud storage에 효율적으로 옮김. 초당 수십기가비트 속도.

스토리지 트렌스퍼 어플리언스 기능 사용사례
- 오프라인 대규모 데이터 세트 이동 솔루션. 구글에서 하드웨어 데이터 전송 및 반송

데이터 스트림 기능 사용사례
- 온프렘, 멀티클라우드의 RDB에서 gcp로 cloud storage, Bigquery로 지속적 복제. 백필을 위한 CDC 옵션 제공. 새 변경사항 전파. 
- 연결시 스키마, 테이블, 열 수준에서 선택적 복제 가능. 
- **Datastream → GCS/PubSub → Dataflow → BigQuery** 형태로 연결함
- 데이터 스트림에서 number → decimal로 통합하는 등 데이터 유형 변환을 통해 복제를 간소화함.
- 정형데이터 지속적으로 온라인 복제*

---

# The Extract and Load Data Pipeline Pattern

추출 및 로드 / 아키텍처 다이어그램 검토
- bq 명령줄로 직접 로드하거나
- 외부 테이블 + biglake 테이블 사용해 bigquery를 통한 데이터 액세스 지원
    - LOAD DATA INTO …

bq 명령줄 도구
- 리눅스 명령어로 넣기 bq load —source_format …. 

bigquery data transfer service 기능 및 사용 사례
- 다양한 소스 데이터(saas, object store, dw)를 쉽게 로드. 

BigLake 추출-로드 외 패턴
- 빅쿼리로 클라우드 스토리지, 구글 시트, 빅테이블 등에도 데이터 쿼리가 됨 (외부 테이블)
- 그리고 빅레이크 테이블을 사용하면 클라우드스토리지, 오브젝트 스토리지 사용 가능
- 빅쿼리 - 정형 데이터 분석을 위한 유연성 제공 / 데이터 이동해서 빅쿼리에서 실행해야함
- 외부테이블 - 데이터 이동이 필요 없음, 액세스 빈도 낮을때 적합
- 빅쿼리 + 외부 테이블 장점 합친거 → 빅레이크 (제한 있음)
- 아파치 애로우 사용
- 데이터가 물리적으로 빅쿼리 외부에 있어도 빅래이크가 백그라운드 메타데이터 캐싱을 활용해 쿼리 성능 향상시킴. 대신 외부에 있어서 쿼리 비용 추정 이런거 어려움.
- 메타데이터로 파티션 찾아서 가는 형식. 스파크로 쿼리할 때도 쿼리 속도 높이는 통계에 엑세스해서 찾기 가능
- 외부테이블 액세스하려면 테이블 자체에 별도 권한 있어야함. 엑세스 관리 어려움. 레이크는 그런거 간단하게 함.
