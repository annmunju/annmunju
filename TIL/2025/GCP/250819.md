# 데이터를 스토리지로 가져오기 위한 데이터 파이프라인 빌드

## 일괄 데이터 파이프라인 빌드 소개

1. EL, ELT, ETL
- Extract
- Load
- Transform

- EL : 데이터를 있는 그대로 시스템으로 가져옴
    - 데이터가 이미 깨끗한 상태일 때.
    - 예시) Cloud Storage에 로그 파일 쌓임 -> BigQuery 네이티브 스토리지로 로드 -> Cloud Composer, Function 등으로 파이프라인 트리거
- ELT : 원시 데이터를 타겟으로 직접 로드하고 필요할 때마다 변환 수행
    - 결과적으로 데이터 무결성을 보장하도록 뷰를 통해 데이터에 엑세스 하는 방법 등
- ETL : 데이터가 타겟에 로드되기 전에 중간 서비스에서 변환이 이뤄짐
    - 데이터를 사용 가능하게 만들기 위해 어떤 종류의 변환이 필요한지 모를때 사용

2. 품질 고려사항
- 정보는 유효하거나, 정확하거나, 안전하거나, 일관되거나, 균일할 수 있음. (일부만 충족할 수 있음)
    - 필요에 따라 해당 조건을 보장하도록 설계함
- 빅쿼리에서 변환 수행 방법
    - 변환하지 않고 뷰를 통해서 결과를 필터링하여 엑세스하도록 할 수 있음

3. BigQuery에서 작업을 수행하는 방법
- where
- group by + having
- null, blank 처리
- countif로 null 아닌 값을 계산
- if문으로 계산에서 특정 값을 사용
- in 으로 누락값 실별 필터링 등
- nullif, countif, coalesce 등 함수로 누락값 채울수 있음
    - 백필 기능 사용 
- 데이터 로드시 체크섬 값으로 파일 무결성 확인
- count로 행 수 
- count distinct 고유 값 수
- format() 함수로 단위를 명확하게 표시하기 + 문서화하기

4. 단점
- 빅쿼리 만으로는 처리할 수 없는 경우, 외부 프로그램을 사용
    - 번역 서비스 수행
    - 기간 집계 및 복잡한 동향 관찰
- pub/sub, cloud storage, spanner, cloud sql 등으로 데이터 추출
- dataflow 등의 파이프라인 이용
    - dataproc, data Fusion 등 활용

5. ETL을 사용해 데이터 품질 문제 해결
- Dataflow 사용시 python, java 이용
- 분석가 및 비기술 사용자 데이터 파이프라인 구성은 data fusion (시각적 인터페이스 제공)
- dataprop은 하둡 워크로드 기반. (복잡한/고가용 파이프라인 구성)

- 유의사항
    - 데이터 계보 (리니지) 유지 : 데이터가 어디서 왔고 어떤 과정을 거쳤는지 계보 남기기
    - 메타데이터 유지 : 적합성 및 식별을 위한 데이터 계보 추적을 위해 라벨 등의 메타데이터 관리
    -> Dataplex, Data Catalog
