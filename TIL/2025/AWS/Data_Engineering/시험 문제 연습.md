- (최소 운영 오버헤드) **SaaS** 어플리케이션에서 Redshift로 지속적으로 **데이터를 전송**하는 방법 
	-> **AppFlow**
- (안전한 방식) **Lambda**가 JDBC를 사용하여 **Redshift** 엑세스 하는 방법 
	-> **Secrets Manager**에 자격증명 저장
- (최소 운영 오버헤드) 온프렘에서 S3으로 파일 전송이 **성공적으로 완료되면 Glue 작업 실행**하는 방법 
	-> **성공할 때** Glue를 실행하는 **EventBridge** 설정
- IAM 역할을 갖춘 페더레이션 사용자가 CloudFormation을 사용해 프로비저닝, 확장 및 종료할 수 있는 상황. 애플리케이션 수명 주기 파악 및 감사 추적을 위해 **SQL 쿼리**로 확인하고자 함 
	-> **CloudTrail Lake**에 이벤트 스토어 만들기. **IAM 역할에 따라 생성되는 별도의 이벤트 유형** 선택. 감사자가 이벤트 데이터 스토어에서 SQL 실행할 CloudTrail Lake 권한 만들기.
	- ==SQL 쿼리 조회 <- CloudTrail Lake 이벤트 데이터 스토어==
	- JSON 형식 저장 <- CloudTrail, CloudWatch Logs
- Glue 데이터 카탈로그의 테이블 버전 업데이트에서 오류. **테이블 버전 리소스 수**가 테이블당 허용된 최대 한도를 초과했다고 표시됨. 
	-> **최대 테이블 버전 수**의 할당량 늘리기
	-> 오래된 버전의 **테이블 스키마**를 검색하고 삭제하기
- Redshift 데이터 웨어하우스를 새로운 리전으로 확장 
	-> Redshift 데이터 공유를 사용하여 모든 리전에 데이터를 공유하거나 특정 리전에 데이터를 공유
- Redshift는 서드파티 자격 증명 공급자(IdP) 등록이 가능 (클러스터 별개는 아니고...)
- DynamoDB의 데이터를 안전한 방식으로 암호화 
	-> 테이블에서 KMS 키를 사용한 서버측 암호화
	-> 항목 업로드 전에 클라이언트 암호화
- (최소 운영 오버헤드) S3에 CSV 데이터 여러 파일로 **파티셔닝** 되며 gzip을 사용해 **압축**된다. 전체 데이터 기록 확인 방법
	-> glue **크롤러** 정의 후 카탈로그 채우고, **redshift serverless** 엔드포인트를 만듦. 데이터 카탈로그를 사용하여 외부 스키마 테이블 정의. redshift spectrum(S3만 조회 됨)으로 쿼리.
- Glue 데이터 카탈로그 암호화 -> **대칭 고객 관리형 키**만 지원!
- EBS 비용을 줄이기 위해서 gp2를 기존보다 줄이는 경우에는 gp3로 줄이고 새 볼륨을 구성하기
- (최소 운영 오버헤드) 여러 DB에서 비일관적인 필드로 구성된 경우지만 레코드를 연결해야 하는 경우
	-> glue 크롤러로 DB 크롤링 후 **FindMatches** 변환으로 중복 레코드 찾기. 변환 평가 후 튜닝
- (비용 효과적) 매일 정해진 시간에 S3에 도착해야 하는 다양한 형식의 데이터 변환, MWAA 사용중
	-> Glue 크롤러로 스키마 스캔 및 식별
	-> (아카이브 된 데이터도) EMR 사용하여 데이터 변환 수행 (redshift보다 비용 절약)
- (비용 효과적) 분산된 버킷에 일주일에 한번 데이터 처리할 오케스트레이션 솔루션
	-> Step Functions, Glue
- 데이터베이스 **지연시간** 확인
	-> CDCIncomingChanges 지표는 특정 시점에 대상에 적용되기를 기다리는 총 변경 이벤트 수를 확인 (X)
	-> CloudWatch Logs를 사용하는 솔루션은 오류, 경고 및 기타 데이터베이스 활동을 식별하거나 모니터링하는 데 도움 (X)
	-> **CDCLatencySource** 지표는 소스 엔드포인트에서 캡처한 마지막 이벤트와 DMS 인스턴스의 현재 시스템 타임스탬프 사이의 간격 (O)
- (가장 빠른 I/O) 하둡에서 스파크 작업을 사용해 데이터 변환 -> 하둡 분산파일 시스템 사용 / 쿼리 presto 사용 -> 사용자 지정 자동 크기조정을 사용하는 균일한 인스턴스 그룹 구성
- (보안) WAF 로그에서 권한 오류 같은거 식별하려면? 
	-> CloudWatch logs로 전송하도록 구성하고 CloudWatch 로그 인사이트 쿼리 편집기로 식별
- **Glue 크롤러**가 하나의 테이블만 생성하도록 하는 솔루션
	-> **객체 형식, 압축 유형 및 스키마**가 각 객체에 대해 동일한지 확인
	-> 객체 이름의 **접두사 구조**가 일관적인지 확인
- (최소 운영 노력) 로그를 S3 버킷에 저장하고 Athena로 로그 쿼리해 트래픽 패턴 분석. 파티셔닝되지 않은 테이블. 데이터 양이 점차 증가할 때 Athena 쿼리 성능 개선 방법
	-> Glue 데이터 카탈로그에 쓰는 분류자가 포함된 **Glue 크롤러 생성**
- (최소 운영 오버헤드) 데이터 레이크 Lake Formation을 사용해 관리 보호 될 때, 이벤트 캡처 솔루션 **QuickSight**로 감사 보고서 생성.
	-> CloudTrail로 추적 생성. Lake Formation에서는 모든 이벤트를 로깅. **CloudTrail** 이벤트 기록에서 **Athena** 테이블 만들기
	-> **Athena**를 데이터 원본으로 사용하여 QuickSight를 사용해 보고서 만들기.
- (최소 지연 시간) IoT 센서. 10초마다 100KB 데이터 전송. 다운 스트림 프로세스는 30초마다 S3 버킷에서 데이터 읽음. S3에 데이터 전송하는 솔루션
	-> Kinesis Data Streams 데이터 수신. Kinesis Client Library를 통해 데이터 주기적으로 처리. 버퍼 단격을 5초간 두기. (데이터 유실 가능성 줄어들고 데이터 배치 처리가 가능)
- (최소 가동 중지) DB 마이그레이션. 
	-> DMS에서 Schema Conversion을 사용해 변환할 수 있음. (O)
	-> SCT를 독립적으로 사용 (DB 인스턴스에서는 못씀!) (가능은 하나 최소 가동 중지?)
- S3 버킷에 이벤트 트리거를 사용해 / **객체를 업로드 하면 인벤토리 측정 프로세스를 수행하고 저장**하는 Lambda를 호출하도록 구성함. 근데 판매 데이터를 업로드 하면 수동 중단될때 까지 계속 인벤토리 측정함. 한 번만 실행하기 위한 솔루션
	-> 버킷을 두개 만들어서 하나는 트리거로 삼고 하나는 저장하면 됨
- (최소 개발과 관리) 많은 계정 감시용 솔루션. 로그를 쿼리할 수 있어야 함.
	-> **CloudTrail Lake**를 사용해 쿼리 분석을 위한 이벤트 데이터 스토어 생성하기.
- Glue 데이터 정확성과 일관성 보장을 위한 검증 규칙 구현 == Glue Data Quality 규칙 세트로 정의
	- 구체적인 검사 하려면 사용자 지정 규칙세트 정의*
- (최소 운영 오버헤드) SageMaker에서 작업중인데, Glue에 카탈로그화된 작은 테이블 쿼리하고 데이터 정리 및 시각화를 활용해 데이터 분석 : 데이터 탐색
	-> SageMaker Data Wrangler : 시각 인터페이스에서 데이터 준비 특성 추출 간소화 및 시각화. - Athena로 데이터 가져오기 가능
- (최소 운영 오버헤드) Redshift로 Aurora PostgreSQL 데이터를 거의 실시간으로 액세스하는 방법
	-> Redshif에서 **페더레이션 쿼리** 사용하여 Aurora 쿼리하기
- Glue로 다양한 소스에서 데이터 파이프라인 실행할 때, 적절한 DPU 용량 결정 방법?
	-> Glue 콘솔에서 작업 실행 모니터링 섹션 검사해서 작업 실행 결과 검토

---

- 데이터 형식
	- csv, parquet(열 형식), ORC, Snappy, Zlib, LZO 및 Gzip (압축 형식) <- Athena를 사용
	- CloudTrail, CloudWatch Logs : json 형식 
- 최소 운영 오버헤드 == 서버리스 위주로 사용하기
- SQL 쿼리
	-  RANK 순위 할당하고 중복되면 건너뛰기됨
	- ROW_NUMBER 지정된 순서에 따라 결과 집합의 각 행에 고유한 행 번호 할당
- PartiQL 
	- 중첩된 데이터 쿼리를 보다 쉽게 지원
- Redshift 명령문
	- CALL : 저장 프로시저 호출 (실행)
	- FATCH : 쿼리에서 반환되는 행의 일부를 검색하는데 사용
	- SHOW : 저장 프로시저 정의를 나열
	- ALTER TABLE DROP PARTITION : 누락된 파티션을 제거하고 새로고침
	- MSCK REPAIR TABLE : 메타데이션에 파티션 추가하기
	- VACUUM : 데이터 파일 압축하고 공간 확보
- Redshift 배포(분산) 스타일
	- AUTO : Redshift가 테이블의 크기와 특성에 따라 자동으로 최적의 분산 스타일을 선택
	- ALL : 모든 노드에 복제하여 저장. 클러스터 각 노드의 첫번째 슬라이스에 전체 상위 테이블 복사본 배치
		- 주로 작은 차원 테이블에서 사용. 조인 시 데이터 이동을 최소화하여 성능 향상
		- 대규모(인 경우) 상위 테이블의 추가 스토리지 비용 발생. 대신 쿼리 성능은 좋음
	- EVEN : 모든 슬라이스에 하위 테이블의 짝수개 행을 임의로 분배. 균일하게 분산시킴.
	- KEY : 상-하위 관계의 테이블을 배포하면 물리적으로 함께 배치됨. 
		- 동일한 분산 키 값을 가진 데이터는 동일한 노드의 동일한 슬라이스에 저장되어, 해당 열을 기준으로 조인하는 쿼리의 성능을 향상
- Redshift 쿼리 편집기
	- v2 : 추가 비용 없이 예약된 쿼리 실행, 구체화된 뷰를 새로고침
- Redshift 데이터 유형
	- SUPER : 네이티브 방식으로 중첩된 JSON 데이터를 저장할 수 있음
- 모니터링 도구 (시각화)
	- QuickSight: 시각화를 구축하고 분석을 수행하고 데이터로 BI를 얻기 위한 서비스
		- 원래는 새로고침 할 때마다 데이터가 요청되는데
		- SPICE(초고속 병렬 인메모리 계산 엔진)을 사용하면 시간 절약 / 비용 최적화로 추가 비용 없이 여러번 재사용 가능
- Lake Formation : 확장 가능하고 유연한 분석 및 기계 학습(ML) 솔루션을 구축하기 위해 데이터를 관리, 액세스 및 공유하는 데 사용되는 서비스
	- 데이터 필터 지원: 열 수준, 행 수준 및 셀 수준 보안 지원
- PII
	- **Macie : S3에 있는 것만 가능. 마스킹은 못함 ㅠㅠ**
	- Glue 작업 - Studio 혹은 DataBrew <- 시각적 인터페이스 (PII 탐지 마스킹 변환까지..)
- 암호화
	- KMS 
		- 키를 통한 서버 측 암호화 (SSE-KMS)
		- 키를 통한 이중 계층 서버 측 암호화 (DSSE-KMS)
	- S3 
		- 암호화 클라이언트: 데이터 업로드 전에 암호화 할 수 있는 클라이언트
	- SSL/TLS : 데이터 전송시 암호화
- 메타스토어
	- AWS Glue 데이터 카탈로그를 Hive 메타스토어로 사용할 수 있음
- 실시간 데이터 / 스트리밍 / 클릭스트림
	- Kinesis Data Streams: 실시간 데이터 수집, 처리, 분석
		- 지표 IteratorAge : Kinesis 데이터 스트림에서 마지막으로 읽은 레코드의 수명이 늘어난다는 의미. 늘어진다... 데이터가 적시에 처리되지 않을 수 있음
		- 재시도 가능함
	- Kinesis Data Firehose: 실시간 데이터 처리, 흐름(전송)
		- 재시도 불가능함
- CloudWatch logs 전송: 구독 필터를 생성해 전송 스트림으로 전송