

## 1.3: 데이터 파이프라인 오케스트레이션
> AWS 서비스를 통합하여 데이터 파이프라인을 생성하는 방법
> 일정 및 종속성을 기반으로 데이터 파이프라인용 AWS 서비스를 구성하는 방법과 이벤트 기반 아키텍처 및 서버리스 워크플로를 사용하여 파이프라인을 설계하는 방법

- 데이터 아키텍처: 조직의 진화하는 데이터 요구 사항을 지원하는 시스템 설계
- 운영 아키텍처: 기능 요구 사항
- 기술 아키텍처: 데이터 수집, 저장, 변환 및 제공되는 방식
- AWS Well-Architected Framework 및 6가지 핵심 요소
	- 모놀리틱 / 마이크로서비스
	- 단일 테넌트 / 다중 테넌트 
		- 테넌트(테넌시) : 서비스를 사용하는 _개별 사용자_  또는 _그룹_ 을 의미
	- 이벤트 기반 아키텍처 / 서버리스 / 컨테이너 사용 여부 등

| **특징**        | **싱글 테넌트(Single-Tenant)**                                                                                                                                                                                                                                                                                                  | **멀티 테넌트(Multi-Tenant)**                                                                                                                                                                                                                                                                                          |
| ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **아키텍처**      | 각 테넌트가 독립된 소프트웨어 인스턴스와 인프라를 사용합니다[1](https://velog.io/@tmdwns1521/%EC%8B%B1%EA%B8%80%ED%85%8C%EB%84%8C%EC%8B%9C-VS-%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%EC%8B%9C)[2](http://blog.naver.com/simula/223705573434?fromRss=true&trackingCode=rss).                                                                             | 단일 소프트웨어 인스턴스와 인프라를 여러 사용자 그룹(테넌트)이 공유합니다.                                                                                                                                                                                                                                                                        |
| **데이터 격리**    | 물리적으로 데이터가 완전히 분리되어 보안성이 높습니다[2](http://blog.naver.com/simula/223705573434?fromRss=true&trackingCode=rss)[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                                                                                               | 각 테넌트의 데이터와 설정은 논리적으로 분리되어 있으며, 다른 테넌트가 접근할 수 없습니다[1](https://dewble.tistory.com/entry/What-is-multi-tenant-architecture)[2](https://wonyong-jang.github.io/bigdata/2021/08/20/BigData-Multitenancy.html).                                                                                                        |
| **보안성**       | 테넌트 간 간섭이 없으며, 데이터 유출 위험이 낮습니다[2](http://blog.naver.com/simula/223705573434?fromRss=true&trackingCode=rss)[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                                                                                              | 데이터 격리를 통해 보안을 유지하지만, 단일 인프라에서 여러 사용자를 운영하므로 추가적인 보안 관리가 필요합니다[3](https://www.devkobe24.com/Architecture/2024-12-11-Multi-Tenant.html)[4](https://it-best.tistory.com/entry/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%ED%8A%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%9D%98-%EC%9E%A5%EC%A0%90).                      |
| **커스터마이징**    | 각 테넌트가 독립적으로 소프트웨어를 수정하거나 확장할 수 있어 커스터마이징이 용이합니다[1](https://velog.io/@tmdwns1521/%EC%8B%B1%EA%B8%80%ED%85%8C%EB%84%8C%EC%8B%9C-VS-%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%EC%8B%9C)[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                        | 각 테넌트는 환경 설정, 대시보드 구성 등 일부 맞춤화가 가능하지만, 완전한 커스터마이징은 제한적일 수 있습니다[1](https://dewble.tistory.com/entry/What-is-multi-tenant-architecture)[3](https://www.devkobe24.com/Architecture/2024-12-11-Multi-Tenant.html).                                                                                                    |
| **운영 비용**     | 관리 및 운영 비용이 상대적으로 높습니다[2](http://blog.naver.com/simula/223705573434?fromRss=true&trackingCode=rss)[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                                                                                                      | 여러 테넌트가 리소스를 공유하므로 비용 효율적입니다. 인프라 구축 및 유지 비용이 절감됩니다[3](https://www.devkobe24.com/Architecture/2024-12-11-Multi-Tenant.html)[4](https://it-best.tistory.com/entry/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%ED%8A%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%9D%98-%EC%9E%A5%EC%A0%90).                                 |
| **확장성**       | 고객 수가 제한적일 경우 적합하며, 확장성은 멀티 테넌트보다 낮습니다[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                                                                                                                                                                  | 테넌트 수 증가에 따라 서버를 추가하여 수평 확장이 가능하며, 사용자 수의 변동에 유연하게 대응할 수 있습니다[5](https://targetcoders.com/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%EC%8B%9C-%EA%B0%9C%EB%85%90%EA%B3%BC-%ED%8C%A8%ED%84%B4/)[6](https://www.ibm.com/kr-ko/topics/multi-tenant).                                                                       |
| **유지 관리**     | 단순한 아키텍처로 인해 유지 관리가 상대적으로 쉽습니다[3](https://maily.so/saascenter/posts/92ze1y1nrep).                                                                                                                                                                                                                                          | 중앙에서 관리되므로 업데이트와 유지 보수가 용이하며, 한 번의 배포로 모든 테넌트에 적용할 수 있습니다[3](https://www.devkobe24.com/Architecture/2024-12-11-Multi-Tenant.html)[6](https://www.ibm.com/kr-ko/topics/multi-tenant).                                                                                                                              |
| **적합한 사용 사례** | 보안 요구사항이 높은 기업, 소규모 조직 또는 특정 고객 맞춤형 서비스 제공 시 적합합니다[1](https://velog.io/@tmdwns1521/%EC%8B%B1%EA%B8%80%ED%85%8C%EB%84%8C%EC%8B%9C-VS-%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%EC%8B%9C)[2](http://blog.naver.com/simula/223705573434?fromRss=true&trackingCode=rss)[8](https://blog.naver.com/xiilab/223506373371?viewType=pc). | SaaS 애플리케이션, 클라우드 서비스 제공업체, 다수의 고객을 대상으로 하는 로그 관리 시스템 등[1](https://dewble.tistory.com/entry/What-is-multi-tenant-architecture)[2](https://wonyong-jang.github.io/bigdata/2021/08/20/BigData-Multitenancy.html)[6](https://www.ibm.com/kr-ko/topics/multi-tenant).                                                 |
| 단점            |                                                                                                                                                                                                                                                                                                                            | - 데이터 격리를 위한 추가 보안 로직 필요  <br>- 특정 테넌트의 리소스 사용량이 다른 테넌트에 영향을 줄 가능성  <br>- 일부 맞춤화 제한[3](https://www.devkobe24.com/Architecture/2024-12-11-Multi-Tenant.html)[4](https://it-best.tistory.com/entry/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%ED%8A%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%9D%98-%EC%9E%A5%EC%A0%90). |

- 데이터 오케스트레이션: 데이터가 수집 서비스에서 처리 서비스를 거쳐 스토리지 위치로 올바르게 흐르도록 보장하는 프로세스
	- Step Functions: 상태 머신 언어를 사용하여 상태, 전환, 오류 처리, 재시도, 입력, 출력, 이벤트 소스, 트리거, 모니터링, 로깅, 테스트, 배포를 설계
	- Lambda

### 예1) 피드백 수신 파이프라인
- 수신된 데이터 유효성 확인
- 데이터 파일을 Parquet 형식으로 변환

### 예2) 스케줄링으로 데이터 보강
- 매일 특정 시간에 모든 피드백을 수신했는지 확인
- Spark 작업을 실행하여 데이터세트를 조인하고 추가 데이터로 데이터를 보강

### 예3) 데이터 웨어하우스로 이관
- 새로 보강된 데이터를 웨어하우스로 로드
- 긍정 / 부정 / 중립의 피드백, 평점에 대한 쿼리를 실행할 수 있음
- 비용 최적화를 위해 Redshift를 S3and 기반 데이터 레이크로 전환하고 Athena로 쿼리를 실행

### 오케스트레이션 도구 / 서버리스 엔진
- Apache Airflow : DAG로 파이프라인 정의
- Step Functions
	- 시각적 설계 도구를 제공(기본 제공 통합을 사용하여 드래그 앤 드롭)하는 서버리스 오케스트레이션 서비스
	- Amazon States Language를 JSON과 함께 직접 사용하여 파이프라인을 정의할 수 있음
	- Spark 사용 예) 입력 파일 경로 전달해 Step Function 상태 머신 트리거 -> 상태 머신 첫 번째 단계가 Lambda 함수 시작 -> 함수를 통해 EMR에서 실행되는 Spark와 상호작용하여 작업 제출 -> Spark 작업상태를 확인하기 전에 상태머신 대기하고 성공/실패 상태로 이동한 후 최종 상태로 업데이트
- AWS Data Pipeline
	- 지정된 간격으로 AWS 데이터 소스와 온프레미스 데이터 소스 간에 데이터를 추출, 변환, 로드하는 기능을 제공
	- 저장된 데이터에 정기적으로 액세스하고, 대규모로 데이터를 변환 및 처리하며, Amazon S3, Amazon RDS, Amazon Redshift, DynamoDB, Amazon EMR과 같은 AWS 서비스에 그 결과를 전송
- Amazon Managed Workflows for Apache Airflow(Amazon MWAA)
- AWS Glue 워크플로
	- 데이터 파이프라인을 구축하기 위한 glue 서비스의 일부로 워크플로를 생성, 시각화, 실행하는 기능을 제공
	- 사용 예) Glue 크롤러를 실행하여 수집한 CSV 파일을 데이터 카탈로그의 새 파티션에 추가 -> Glue Spark 작업 실행하고 카탈로그 사용해 새 데이터 읽음 -> CSV 파일에 있는 데이터를 Parquet 파일로 변환 -> 변환된 파일을 카탈로그에 추가 -> (병렬 실행) 1. 데이터 집계 후 결과를 DynamoDB 테이블에 작성 , 2. 새 데이터를 기존 참조 데이터세트에 조인하는 보강된 데이터세트 생성 -> Glue python 셸 작업 실행하여 작업 성공 혹은 실패에 대한 알림을 보냄
	- 사용 예: Hive + EMR 사용) Boto3 라이브러리를 사용하여 Amazon EMR 또는 Amazon Simple Queue Service(Amazon SQS)와 같은 다른 AWS 서비스와 상호 작용하는 AWS Glue Python 셸 작업을 실행하여 SQS 대기열에 파일을 기록
### 이벤트 기반 파이프라인
- 예1: 새 피드백 파일에 대한 응답으로 실행되는 이벤트 기반 파이프라인
	- S3 버킷에 기록될 때 시작하는 이벤트 알림을 사용
	- 파이프라인이 트리거되고 첫 번째 단계는 파일을 읽은 다음 나열된 다음 파일이 존재하는지 확인

### 파이프라인 실패 처리
- 데이터 형식 오류(품질 문제) - 하드 실패
- 코드 오류 -> 프로그래밍 개념 적용 - 하드 실패
- 엔드포인트 오류 -> 재시도 가능 - 소프트 실패 -> 하지만 다시 시도할때도 권한과 같은 이슈로 불가능하다면 하드 실패
-> 데이터 파이프라인 내부 종속성 / 파이프라인 간 종속성 고려
- 실패 재시도 전략
	- Apache Airflow, Step Functions와 같은 오케스트레이션 도구는 재시도 횟수, 재시도 간격, 백오프 비율을 지정할 수 있음
	- 백오프 비율 값 지정: 특정 작업이나 상황에서 실패가 발생했을 때, 이를 재시도하기 전에 일정 시간 동안 기다리는 값을 지정. 그래서 재시도 지연시간이 증가함. (재시도 간격 10초, 백오프 비율 1.5일 때 10 -> 15 -> 22.5)
- 실패에 대한 모니터링 & 알림 
	- SNS 주제 생성 -> 주제 구독

---

## 데이터 아키텍처
- **정의**: 조직의 진화하는 데이터 요구 사항을 지원하는 시스템 설계
- **측면**:
    - 운영 아키텍처 (기능 요구 사항)
    - 기술 아키텍처 (데이터 수집, 저장, 변환, 제공 방식)
- **고려 사항**:
    - 모놀리식 vs 마이크로서비스
    - 단일 테넌트 vs 다중 테넌트
    - 성능, 보안
    - 이벤트 기반 아키텍처, 서버리스, 컨테이너
    - 제어 기능, 유연성, 비용

## 데이터 아키텍처 유형
- 데이터 웨어하우스, 데이터 레이크, 데이터 레이크 하우스, 데이터 스택, Lambda, Kappa, 데이터 메시 등

## 데이터 파이프라인 오케스트레이션
- **정의**: 데이터가 수집 서비스 -> 처리 서비스 -> 스토리지 위치로 올바르게 흐르도록 보장하는 프로세스
- **핵심 개념**:
    - 데이터 파이프라인 정의 (특정 순서로 실행되는 데이터 처리 태스크 모음)
    - 워크플로 (태스크 순서 지정)

## 오케스트레이션을 위한 서버리스 AWS 서비스
- Step Functions, Lambda

## Step Functions
- 상태 머신 언어를 사용하여 상태, 전환, 오류 처리, 재시도, 입력, 출력, 이벤트 소스, 트리거, 모니터링, 로깅, 테스트, 배포 설계
- 데이터 파이프라인 워크플로에 대한 태스크 실행 자동화
- 다양한 태스크 간의 종속성 관리
- 태스크와 파이프라인이 예상대로 실행되도록 보장

## 데이터 파이프라인 예시
1. **피드백 유효성 검사**: 수신 데이터 유효성 확인, Parquet 형식으로 변환
2. **데이터 조인 및 보강**: 매일 특정 시간에 실행, 모든 피드백 수신 확인, Spark 작업 실행, 데이터세트 조인 및 보강
3. **데이터 웨어하우스 로드**: 새로 보강된 데이터를 데이터 웨어하우스로 로드

## Directed Acyclic Graph (DAG)
- Apache Airflow에서는 파이프라인을 DAG로 정의해야 함
- Step Functions는 파이프라인이 반드시 DAG일 것을 요구하지 않음

## 파이프라인 트리거
- **일정 기반**: 특정 시간에 실행
- **이벤트 기반**: 특정 이벤트 발생 시 실행 (ex: S3에 파일 업로드)

## 파일 배치 처리
- 파일 배치의 마지막에 파일 배치를 구성하는 다른 파일에 대한 정보가 포함된 매니페스트 파일 필요
- manifest라는 이름으로 시작하는 파일이 S3 버킷에 기록될 때만 시작하는 S3 이벤트 알림 사용

## 파이프라인 단계 실패 처리
- **일반적인 이유**:
    - 데이터 품질 문제 (CSV 파일 필요 but JSON 파일 수신)
    - 코드 오류 (로직 또는 구문 오류)
    - 엔드포인트 오류 (네트워크 오류, 권한 부족)
    - 종속성 오류 (파이프라인 내부/간)

## 실패 재시도 전략
- 재시도 횟수, 재시도 간격, 백오프 비율 지정 (Apache Airflow, Step Functions 등)
- **백오프 비율 예시 (Step Functions)**:
    - 재시도 간격을 10초, 백오프 비율을 1.5로 지정
    - 1차 재시도: 10초 대기
    - 2차 재시도: 15초 대기
    - 3차 재시도: 22.5초 대기

## AWS 알림 서비스 (Amazon SNS)
- 문제 또는 실패에 대한 알림 발송
- 이메일 알림을 보내도록 구성 가능 (Amazon SNS 주제 생성 및 이메일 주소 구독)

## 데이터 파이프라인 오케스트레이션을 위한 AWS 서비스
- **서버리스 오케스트레이션 엔진**: AWS Data Pipeline, Step Functions
- **오픈 소스 관리형**: Amazon Managed Workflows for Apache Airflow (Amazon MWAA)
- **서비스별 오케스트레이션**: AWS Glue 워크플로

## 각 솔루션 선택 기준
- 사용 사례, 요구 사항, 관리 작업, 통합 작업, 로깅, 오류 처리, 성능, 비용 고려

## AWS Data Pipeline
- 지정된 간격으로 AWS 데이터 소스와 온프레미스 데이터 소스 간에 데이터 추출, 변환, 로드
- Amazon S3, Amazon RDS, Amazon Redshift, DynamoDB, Amazon EMR과 같은 AWS 서비스에 결과 전송
- 온프레미스 데이터베이스와 같은 다른 JDBC 데이터 스토어에서 읽고 쓸 수 있음
- Amazon EC2, Amazon ECR 및 온프레미스 컴퓨팅 리소스를 사용하여 데이터 변환 작업 실행

## Step Functions
- 시각적 설계 도구를 제공하는 서버리스 오케스트레이션 서비스
- 로우코드 접근 방식을 사용하여 데이터 파이프라인 및 서버리스 애플리케이션 개발
- 기본 제공 통합을 사용하여 드래그 앤 드롭하거나, Amazon States Language를 JSON과 함께 직접 사용하여 파이프라인 정의

## Step Functions를 이용한 Spark 작업 오케스트레이션 예시
1. 입력 파일 경로를 전달하여 Step Function 상태 머신 트리거
2. 상태 머신의 첫 번째 단계가 Lambda 함수 시작
3. Lambda 함수가 Amazon EMR에서 실행되는 Spark와 상호 작용하여 Spark 작업 제출
4. 상태 머신이 Spark 작업 상태를 확인하기 전에 몇 초 동안 대기
5. 작업 상태에 따라 상태 머신이 성공 또는 실패 상태로 이동
6. 상태 머신이 작업이 완료될 때까지 몇 초 동안 대기. 작업이 완료되면 상태 머신이 최종 상태로 업데이트

## AWS Glue 워크플로
- 데이터 파이프라인이 AWS Glue 구성 요소만 사용하는 경우 훌륭한 선택
- 워크플로를 생성, 시각화, 실행하는 기능 제공
- 워크플로 그래프에 트리거를 추가하고 각 트리거에 대해 감시되는 이벤트와 작업을 정의하여 워크플로 구축

## AWS Glue 워크플로 예시
- AWS Glue 크롤러를 실행하여 수집된 CSV 파일을 데이터 카탈로그의 새 파티션에 추가
- AWS Glue Spark 작업을 실행하고 카탈로그를 사용하여 새 데이터 읽기
- CSV 파일에 있는 데이터를 Parquet 파일로 변환
- 새 AWS Glue 크롤러를 실행하여 변환된 Parquet 파일을 데이터 카탈로그에 추가

## AWS Glue 워크플로에서 Hive 작업 실행 (Amazon EMR 필요)
- Boto3 라이브러리를 사용하여 Amazon EMR 또는 Amazon Simple Queue Service(Amazon SQS)와 같은 다른 AWS 서비스와 상호 작용하는 AWS Glue Python 셸 작업 실행 (Amazon SQS 대기열에 파일을 기록)

## Step Functions를 사용한 복잡한 ETL 워크플로 오케스트레이션
- 온라인 사용자 참여와 예상 판매 수익 및 기회 간의 상관 관계 분석 예시
- Step Functions를 사용하여 여러 AWS Glue 작업을 조정하여 분석할 데이터를 혼합하고 준비

## 서버리스 데이터 레이크 구축 (Amazon S3 기반) 예시
1. 다양한 방법으로 Amazon S3에 데이터 수집 및 저장 (Amazon Kinesis Data Firehose, AWS DMS, DataSync)
2. 데이터를 원시 영역이라는 S3 버킷으로 수집
3. 데이터 카탈로그에서 해당 스키마를 카탈로그화 (Amazon S3에 의해 호출된 Lambda 함수를 사용하여 데이터를 카탈로그화하는 AWS Glue 크롤러 시작)
4. AWS Glue ETL 작업을 시작하여 데이터를 처리하고 처리된 영역이라는 또 다른 S3 버킷으로 출력
5. AWS Glue ETL 작업은 데이터를 Parquet 형식으로 변환하여 처리된 S3 버킷에 저장
6. ETL 작업을 수정하여 보다 세분화된 파티셔닝, 압축 또는 데이터 보강과 같은 다른 목표 달성
7. ETL 작업이 완료되는 즉시 또 다른 CloudWatch 규칙이 Amazon SNS 주제를 사용하여 이메일 알림 전송 (데이터가 성공적으로 처리되었음을 나타냄)

## Apache Airflow 및 Amazon MWAA
- Apache Airflow: 워크플로를 작성, 모니터링, 예약하는 데 도움이 되는 오픈 소스 오케스트레이션 소프트웨어
- Amazon MWAA: AWS의 Apache Airflow 관리형 버전
- 데이터 파이프라인이 DAG로 생성 (Python 사용)
- AWS Glue 태스크, Lambda 함수 또는 데이터 ETL 파이프라인 내의 다른 사용자 지정 태스크와 같은 태스크를 실행

## AWS Glue 워크플로
- AWS Glue 크롤러는 매일 실행되어 데이터 레이크의 원시 영역에서 새로 수집된 데이터를 데이터 카탈로그에 추가
- 크롤러가 완료되면 AWS Glue ETL 작업이 시작되어 원시 CSV 데이터를 Parquet 형식으로 변환한 후 데이터 레이크의 큐레이팅된 영역에 기록
- AWS Glue 작업이 완료되면 AWS Glue 크롤러가 시작되어 새로 변환된 데이터를 큐레이팅된 영역, 그리고 데이터 카탈로그에 추가

## 여러 AWS 리전에 있는 데이터에 대한 쿼리
- 한 리전에서 AWS Glue 크롤러를 실행하여 모든 리전의 데이터세트를 카탈로그화
- 데이터가 크롤링되면 데이터 과학자가 Athena 쿼리 실행

## Step Functions를 사용하여 데이터 변환 파이프라인 오케스트레이션
- JSON 데이터를 워크플로의 첫 번째 상태에 전달되는 입력 텍스트로 포함하여 상태 머신 시작
- 워크플로의 첫 번째 상태는 이 입력 데이터를 사용하고 구성된 기능을 수행
- Lambda 함수를 실행하고 함수가 JSON 데이터를 수정한 다음 수정된 JSON 데이터를 워크플로의 다음 상태로 전달
- EventBridge를 사용하여 일정 기반 또는 이벤트 기반으로 Step Function 시작 또는 Step Functions API를 호출하여 필요 시 Step Function 시작

## Step Functions 단계별 설명
1. 파일이 S3 버킷에 업로드되면 CloudWatch 이벤트가 트리거
2. CloudWatch 이벤트는 버킷에 새로 업로드된 파일의 위치가 포함된 JSON 객체를 전달하는 상태 머신 시작
3. 작업이 성공했는지 여부 (선택)
4. 작업 상태 필드가 성공으로 설정되었으면 AWS Glue 크롤러 실행 단계로 분기
5. 작업 상태 필드가 실패로 설정되었으면 작업 실패로 분기
6. AWS Glue 크롤러 실행 단계에서는 Lambda 함수가 시작되고, 이 함수는 이전 Lambda 함수가 Parquet 파일을 기록한 위치에 대해 실행되도록 AWS Glue 크롤러를 시작
7. 작업 실패 단계에서는 상태 머신의 실행을 중지하고 실행을 실패로 표시
8. 상태 머신은 catch 문을 사용하여 상태 머신 실행이 오류 상태임을 감지하면 오류 단계 실행
9. 오류 단계에서는 또 다른 Lambda 함수가 트리거되어 데이터 엔지니어링 팀에 파일 처리가 실패했음을 알리는 알림 전송

## 일반적인 기계 학습 모델 개발 워크플로
- 데이터 준비 -> 모델 훈련 및 튜닝 -> 프로덕션 -> 배포

## 데이터 파이프라인 단계
1. **수집**: 적절한 도구가 데이터를 수집하고 조정
2. **저장**: 데이터가 영구적 방식으로 저장
3. **변환/처리/분석**: 데이터 처리 및 분석 솔루션이 스토리지로부터 데이터를 가져와서 작업을 수행한 후 흔히 새로운 위치에 데이터를 다시 저장
4. **제공/시각화**: 비즈니스 사용자가 데이터를 활용할 수 있도록 데이터가 시각화

## 성능, 가용성, 확장성, 복원력, 내결함성을 위한 데이터 파이프라인 구축 모범 사례
- Spark, Amazon EMR 또는 AWS Glue와 같은 분산 처리 프레임워크를 사용하여 대량의 데이터 처리 및 리소스 클러스터 전체에 걸쳐 병렬 처리 실행
- 최적의 성능 및 비용 효율성을 보장하기 위해 데이터 파이프라인에서 자동 크기 조정 구성
- 여러 처리 리소스에 데이터를 분산하기 위해 적절한 데이터 파티셔닝 기술 구현
- 데이터를 저장하는 데 Amazon S3 또는 Amazon Elastic File System(Amazon EFS)과 같은 내결함성 스토리지 서비스 사용
- 데이터 가용성을 보장하고 재해 복구에 도움이 되도록 백업, 전략 및 계획을 구현하여 Amazon S3or 또는 AWS Backup으로 데이터 보호
- CloudWatch를 사용하여 데이터 파이프라인의 상태 및 성능 모니터링 (경보 및 알림 설정)
- Step Functions 또는 AWS Glue 워크플로를 사용하여 데이터 파이프라인 내에서 오류 처리 및 재시도 메커니즘 구현
- 데이터 검증 및 품질 검사를 구현하고 자동화된 테스트, 버전 제어 및 배포 프로세스를 포함
- 문제 해결, 유지 관리, 확장성을 위해 데이터 파이프라인의 여러 단계 또는 구성 요소를 단위로 격리 (Lambda, AWS Glue 또는 컨테이너화 기술 사용)
- 변경 사항을 효율적으로 배포할 수 있도록 데이터 파이프라인에 대해 CI/CD 방식 구현