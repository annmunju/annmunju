
## 1.2: 데이터 변환 및 처리
특정 요구 사항을 충족하는 ETL 파이프라인을 생성
비정형 및 정형 데이터의 볼륨, 속도, 다양성을 다루는 방법
클라우드 컴퓨팅 및 분산 컴퓨팅을 위해 데이터를 설계, 변환, 처리하는 방법

### 쿼리 및 모델링
- 개념, 논리, 물리, 정규화
- OLTP (온라인 트랜잭션 처리) : 데이터 최신상태에 중점. 주문 처리, 결제 처리, 고객 데이터 관리 등.
- OLAP (온라인 분석 처리) : 복잡한 데이터 분석 및 보고에 최적화. 고객 행동 예측, 추세 분석 등.

### 데이터 변환
- 올바른 유형으로 매핑
- 데이터 스키마 변경 및 정규화 적용
- 배치 데이터 변환
- 분산 컴퓨팅을 사용한 변환 : Lambda, Amazon EMR, AWS Glue, Amazon Redshift
- 병렬 컴퓨팅을 이용한 변환 : Amazon EMR, AWS Batch, AWS Step Functions
- 서버리스를 이용한 변환 : Glue
- 빅데이터 처리 도구 : Spark, Hive, Apache Hudi, Apache HBase, Presto, Pig (AWS EMR)
- Flink : SQL 명령을 사용하여 기본 데이터 변환 수행 -> EMR, Glue : 더 복잡한 데이터 변환 수행

### Spark 사용해 데이터 처리하는 방법 
1. EMR 클러스터 시작
2. Spark 설정 및 프로그램 만들기 (구성파일 수정하여 워크로드 요구사항 기반으로 메모리 할당)
3. 클러스터에 보내 실행. 모니터링과 최적화
4. 결과 저장하기
-  Amazon EMR의 경우 Spark를 실행하려는 클러스터에 특정 구성이 필요하므로 데이터 처리에 하둡 에코시스템을 사용할 때 이용하는 것이 좋음

| **특징**            | **AWS Glue**                          | **AWS EMR**                                                 |
| ----------------- | ------------------------------------- | ----------------------------------------------------------- |
| **서비스 유형**        | 서버리스 ETL 서비스                          | 관리형 빅데이터 플랫폼                                                |
| **주요 사용 사례**      | 데이터 정리, 보강, 이동 등 간단한 ETL 작업           | 대규모 분산 데이터 처리, 머신 러닝, 실시간 데이터 스트리밍 분석                       |
| **지원 기술 및 프레임워크** | 내장된 ETL 기능 및 AWS Glue Data Catalog 활용 | Apache Spark, Hive, Pig, HBase, Presto 등 다양한 오픈소스 빅데이터 툴 지원 |
| **유연성**           | 제한적 (Glue의 기본 제공 기능에 의존)              | 높은 유연성 (클러스터 구성 및 다양한 인프라 선택 가능)                            |
| **관리 요구사항**       | 클러스터 관리 불필요 (완전관리형)                   | 클러스터 관리 필요                                                  |
| **비용 모델**         | 사용량 기반 과금 (PAYG)                      | 인프라 및 클러스터 구성에 따라 비용 조정 가능                                  |
| **확장성**           | 제한적 (Glue 워커 유형에 따라 메모리 제약 있음)        | 페타바이트 수준 확장 가능, 다양한 EC2 인스턴스 유형 활용 가능                       |
| **데이터 형식**        | 구조화된 데이터에 적합 (CSV, JSON 등)            | 반구조화 및 비정형 데이터 처리 가능                                        |
| **실시간 처리 능력**     | 제한적 (100초 처리 창 제한 등)                  | 실시간 스트리밍 분석 지원                                              |
| **데이터 카탈로그 통합**   | AWS Glue Data Catalog를 기본적으로 사용       | Glue Data Catalog와 통합 가능                                    |

### 예1) 키바나 대시보드 데이터 시각화
1. kinesis 설치 후 kinesis data firehose로 지속적으로 전송하도록 구성
2. kinesis data firehose가 s3 버킷으로 스트림의 데이터를 전송하도록 구성
3. glue를 이용해 카탈로그화 (데이터 레이크 솔루션의 일부로 사용)
4. firehose 처리를 위해 스트림의 데이터를 flink로 전송하도록 구성
5. flink를 이용해 스트림 데이터 집계 후 다른 firehose로 보냄
6. firehose에서 사용자 보고서에 사용하기 위해 인덱싱될 데이터를 opensearch로 보냄
7. kibana가 opensearch에 연결해 사용자를 위한 로그 레코드의 시각화 구축

### 예2) 과거 트랜잭션을 판매 실적 보고서 데이터와 조인
1. Redshift 클러스터로 데이터 처리
2. Redshift SQL을 사용하여 테이블을 조인하고 Redshift Spectrum을 사용하여 S3에서 과거 트랜잭션 데이터를 위한 외부 테이블 생성

### 예3) 변환 실패 및 성능 문제 해결 방법
- 데이터 변환시의 AWS 서비스에서 생성된 로그 확인
- 데이터 품질 및 무결성 확인
- 소스 데이터에서 변환 로직을 검증해 매핑, 필터, 집계 및 계산이 모두 바른지 확인

### 예4) 다른 시스템에서 데이터를 사용할 수 있도록 API 생성
- 데이터 저장 위치 파악
- API gateway를 사용하여 API 생성
- 보안과 인증 설정 : API Gateway, Lambda 함수에 대한 액세스 권한 제어로 보호
- 캐싱 및 성능 최적화 : ElastiCache 또는 API Gateway 내장 캐싱기능 사용해 응답 캐시하고 지연시간 줄일 수 있음.


---

## 목표
- 원시 데이터를 다운스트림 사용 사례에 유용한 형식으로 변경
- 데이터를 보고서, 분석, 기계 학습 등에 사용 가능하게 만들기

## 주요 도구 및 개념
- **쿼리**: 데이터 검색 및 조작의 기본 요소
- **데이터 모델링**:
    - 데이터를 유용한 방식으로 구성하기 위한 설계 및 계획
    - 개념, 논리, 물리, 정규화 모델 이해
    - 배치 분석 데이터 및 데이터 볼트 모델링 기술 이해
- **변환**:
    - 데이터 유형 매핑 (문자열 -> 숫자/날짜)
    - 레코드 표준 형식으로 변환
    - 잘못된 데이터 제거
    - 데이터 스키마 변경, 정규화, 대규모 집계 적용 (보고, 기계 학습용)
    - 데이터 통일 및 통합, 조작/보강/저장, 가치/확장성/신뢰성 추가, 비용 효율성 향상

## OLTP vs OLAP
- **OLTP (온라인 트랜잭션 처리)**:
    - 실시간 업데이트, 트랜잭션 처리 최적화
    - 최신 데이터 중점
    - 정규화/비정규화 모델 사용
    - 낮은 스토리지 요구사항, 짧은 응답 시간
    - 주문/결제 처리, 고객 데이터 관리 등에 적합
- **OLAP (온라인 분석 처리)**:
    - 복잡한 데이터 분석, 보고 최적화
    - 최신 & 과거 데이터 중점
    - 스타 스키마, 눈송이 스키마 등 사용
    - 테라바이트~페타바이트 대용량 스토리지 요구
    - 고객 행동 예측, 추세 분석 등에 적합

## 데이터 준비 (랭글링)
- 최종 데이터 분석에 유용한 데이터 파이프라인 설계 및 구축
- 계산 필드 추가, 필터 적용, 필드명/데이터 유형 변경, 테이블 조인 등

## AWS 서비스 활용
- **클라우드 컴퓨팅**: Lambda, Amazon EMR, AWS Glue, Amazon Redshift
- **분산 컴퓨팅**: Amazon EMR, AWS Batch, AWS Step Functions (여러 노드에 걸쳐 병렬 처리)
- **서버리스 처리**: AWS Glue (Python/Spark 엔진)

## AWS Glue
- **구성 요소**:
    - 데이터 카탈로그 (데이터셋 논리적 뷰, 메타데이터 캡처)
    - 크롤러 (데이터 소스 검사, 스키마 자동 추론)
- S3 버킷에 복제된 데이터베이스 데이터에 대한 논리적 뷰 제공
- Athena, EMR, Glue ETL 엔진에서 카탈로그 객체 참조 가능

## Amazon EMR
- Spark, Hive, Apache Hudi, HBase, Presto, Pig 등 빅데이터 처리 도구 실행 관리형 서비스
- EMR 클러스터 시작 -> 프라이머리 노드 연결 -> Spark 구성 -> 데이터 준비 및 S3 저장 -> Spark 애플리케이션 개발 (Scala, Python, Java) -> Spark-submit으로 실행
- 클러스터 전체에서 Spark 애플리케이션 시작 및 관리
- 애플리케이션 진행 상황, 리소스 사용률 모니터링
- 데이터 파티셔닝, 캐싱, Spark 구성 튜닝 등 최적화 기술 활용
- 데이터세트 크기, 처리 요구 사항에 따라 클러스터 확장/축소
- 처리된 데이터를 S3, Redshift, RDS 등에 저장

## 서비스 선택 기준
- AWS Glue: 완전 관리형 ETL 서비스, 데이터 정리, 보강, 이동에 적합
- Amazon EMR: Hadoop 에코시스템 사용, 환경에 대한 더 많은 제어가 필요할 때 적합 (Spark, Hive 등 추가 프레임워크 설치 필요)

## 스트리밍 데이터 처리
- Amazon Managed Service for Apache Flink: SQL 명령으로 기본 데이터 변환

## 파이프라인 구축 예시 (IoT 데이터)
- Kinesis Data Firehose로 스트리밍 IoT 데이터 S3에 수집
- Lambda 함수로 민감 데이터 제거 및 변환 후 S3 저장

## 문제 해결 및 성능 최적화
- AWS 서비스에서 생성된 로그 확인
- 데이터 품질 및 무결성 확인
- 소스 데이터에서 변환 로직 검증 (매핑, 필터, 집계, 계산)
- Glue 개발/디버깅 모드 활용, 작은 데이터세트 사용
- 코드 및 쿼리 프로파일링/분석, 병목 현상 식별
- 효율적인 알고리즘, 파티셔닝 전략 적용
- 메모리 할당, 실행기 코어 수 등 리소스 설정 최적화
- 캐싱 통합
- 증분 처리 기술 구현 (새/수정 데이터만 처리)
- 재시도 메커니즘 통합 (일시적인 실패/오류 처리)
- 테스트 환경 구축 및 다양한 테스트 (단위, 통합, 엔드투엔드) 수행

## 추가 고려 사항
- 보안 (JDBC, ODBC 연결)
- 데이터 API 생성 (API Gateway, Lambda 활용)
- 보안, 인증 (IAM, Certificate Manager, API 키, OAuth 등)
- 캐싱, 성능 최적화 (ElastiCache, API Gateway 캐싱)
- 모니터링 (CloudWatch)
- 버전 관리 (API Gateway)
- 확장 및 가용성 (Lambda 자동 크기 조정, API Gateway 구성)
- 테스트 및 검증 (CodePipeline, CodeBuild 활용, 자동화)