- 학습 목표
	- 대규모 데이터 마이그레이션의 과제를 파악합니다.
	- AWS DataSync, Amazon S3 File Gateway, AWS Snowball Edge 서비스와 그 이점을 설명합니다.
	- AWS로의 대규모 데이터 마이그레이션을 위한 계획 요구 사항을 설명합니다.
	- 대규모 데이터를 AWS로 마이그레이션하기 위한 예비 마이그레이션 계획을 개발합니다.

## 개념
- 대용량 데이터세트
	- 100테라 이상
	- 100kB 5천만 개 이상의 파일
- 사용 기술
	- DataSync
	- Snow Family 디바이스
	- 소규모의 경우 CLI (sync, glacier)
- 대규모 마이그레이션이 어려운 이유
	- 스크립트 빌드 및 배포
		- 마이그레이션 프로세스에는 배포하고 유지 보수하는 스크립트를 포함해야함. 누가 관리할 것인지 등을 지정해야함
	- 데이터 암호화 및 검증
		- 데이터 무결성 확인하는 방법도 있어야함. 데이터 누락되면 마이그레이션 또 해야할지도...
	- 오류 복구
		- 오프라인 상태가 되거나 네트워크 연결이 끊어질 수 있음. 이런 실패 감지하도록, 복구하도록 결정
	- 네트워크 가용성 처리
		- 네트워크 대역폭 가용성의 변동을 고려. 미리 계획할 때 평가하고 결정해두고 최적화
	- 성능 보장

## AWS 서비스
### 1) DataSync 
- 250312 DataSync - Primer 참고
- 인터넷 대역폭과 전송 속도를 고려해서 일정을 배분할 수 있으며, 여러번 데이터를 이전해야하는 상황에서는 해당 서비스를 이용하는 것이 유리

### 2) S3 File Gateway
- 최근에 저장되거나 엑세스한 데이터에 **지연시간이 짧은 엑세스**를 제공하고 S3에 원활하게 데이터 전송
- 사용
	- **AWS에 저장된 데이터에 대한 지연 시간이 짧은 액세스**
	- **온프레미스 파일 스토리지를 Amazon S3 서비스로 계층화**
	- **파일 메타데이터 보존**
	- **데이터 레이크 채우기**
- 초기 복제 이후 생성된 데이터를 추가로 복제해야 하는 경우에도 사용

- 인터넷을 사용해서 데이터를 옮기는데 드는 시간 (1, 2 서비스)

|            | **1 Gbps** | **2** **Gbps** | **5 Gbps** | **10 Gbps** |
| ---------- | ---------- | -------------- | ---------- | ----------- |
| **100 TB** | 12 일       | 6 일            | 3 일        | 30 시간       |
| **500 TB** | 58 일       | 29 일           | 12 일       | 6 일         |
| **5 PB**   | 2 년        | 1 년            | 116 일      | 58 일        |
| **10 PB**  | 3 년        | 2 년            | 232 일      | 116 일       |

### 3) Snowball Edge
- 250311 Snowcone - Primer 참고
- 일회적이고 빠른 속도로 이관하는 경우. 위에 제시한 인터넷을 사용하는 것보다 빠르고 저렴하게 적용해야 하는 경우.

## 계획 작업
- 구성 요소
	- 비즈니스 목표 및 목적
		- 고려사항: 속도, 비용, 일회인지 다회인지, 전환 기간이나 이벤트 및 마일스톤
	- 온프레미스 검색 수행
		- 고려사항: 데이터의 세부 정보(파일 크기, 데이터 크기, 수, 위치 구성 유형 등), 데이터 액세스 방법, 파일 공유 프로토콜, 사이트 요구 사항, 인터넷 대역폭, 가상 머신 인프라 구비, 데이터 사용 시점, 담당자
	- AWS 대상 선택
		- 고려사항: 선택한 대상은 무엇이며 리전은 어디?
- 인터넷 속도 별로 온라인 전송 시간 상이하고, 디바이스 이용하는 경우 대부분 25~30일 소요

## 사용 사례
![[src/Pasted image 20250313123533.png]]
