---
marp: true
title: 견고한 데이터 엔지니어링 (7장 요약)
description: 
author: annmunju
theme: default
paginate: true
---

# 견고한 데이터 엔지니어링
## 7장 요약

> 데이터 수집

---

# 7.1 데이터 수집이란?
> 데이터 수집과 데이터 통합의 차이
> 데이터 파이프라인 정의

- 데이터 파이프라인은 데이터 엔지니어링 수명 주기의 단계를 통해 데이터를 이동시키는 아키텍처, 시스템 및 프로세스의 조합이다.

---

# 7.2 수집 단계의 주요 엔지니어링 고려 사항

## 7.2.1 유한 데이터 vs 무한 데이터
- 비즈니스 프로세스는 데이터를 개별 배치로 인위적으로 잘라내 제한을 두어왔음.
- 모든 데이터는 유한해질 때 까지 무한함

## 7.2.2 빈도
- 배치 : 빈번함
- 마이크로 배치 : 꽤 빈번함
- 실시간 : 매우 빈번함 (스트리밍과 같은 의미로 사용)

---

## 7.2.3 동기 수집 vs 비동기 수집
- 동기 수집 : 원천 -> 수집 -> 대상(스토리지) 가 복잡한 의존성을 가지며 밀접하게 결합됨.
    - 중간 과정 중 하나라도 실패하면 다시 작업해야함.
- 비동기 수집 : 개별 이벤트 수준에서, 데이터가 들어오는 즉시, 처리할 수 있는 리소스(컴퓨터 자원)가 있다면 바로 처리

## 7.2.4 직렬화와 역직렬화
> 원천으로부터 데이터를 인코딩하고 송신 및 중간 저장 단계를 위해 데이터 구조를 준비

---

## 7.2.5 처리량과 확장성
- 처리량 확장에 서버, 샤드, 워커 등을 지원하는 관리형 서비스를 사용

## 7.2.6 신뢰성과 내구성
- 데이터 손실에 따른 영향과 비용으로 리스크를 미리 평가
- 직접 비용과 간접 비용 평가

---

## 7.2.7 페이로드
- 수집하려는 데이터셋의 종류, 형태, 크기, 스키마, 데이터 유형, 메타데이터 특성 알기
1. 종류(kind) : type, format
2. 형태(shape) : 표, json, txt, image, audio
3. 크기(size) : 바이트 수
4. 스키마와 데이터 유형
    - 애플리케이션의 클래스 구조로 감싸진 경우가 있고
    - API로 감싸져 있는 경우가 종종 있어, 애플리케이션 코드를 이해해야 하는 경우가 종종 있음
    - 업스트림 및 다운스트림 스키마 변경 검출과 처리
5. 메타데이터

---

### 업스트림 / 다운스트림 스키마 변경 검출과 처리

#### a. 개념
- **업스트림(Upstream)**: 데이터를 생성/제공하는 쪽 (예: 소스 DB, API).
- **다운스트림(Downstream)**: 데이터를 소비/활용하는 쪽 (예: DWH, ML 모델, 대시보드).

#### b. 스키마 변경 유형
- 열 추가 (Add column)
- 열 삭제 (Drop column)
- 열 타입 변경 (Change type)
- 열 이름 변경 (Rename column)
- 열 순서 변경

---

#### c. 변경 검출 방법
- 메타데이터 비교 (`INFORMATION_SCHEMA` 등)
- DWH 시스템 테이블 조회 (BigQuery, Snowflake 등)
- CDC(Change Data Capture) 로그 감지 (Debezium, Kafka Connect)
- 스키마 레지스트리 (Kafka, Glue, Confluent)

#### d. 변경 처리 전략
- **호환 가능 (추가)** → 무시하거나 `NULL` 처리, 자동 수용
- **호환 불가능 (삭제/타입 변경/이름 변경)**  
  - 스키마 에볼루션 지원 시스템 활용 (Hive, Delta Lake, Iceberg)  
  - 변환 레이어 도입 (새 스키마 ↔ 표준 스키마 매핑)  
  - 다운스트림 코드/쿼리 수정  
---

#### e. 실무 패턴
- 스키마 호환성 정책 정의 (예: 열 추가 허용, 삭제는 협의 필요)
- 자동 알림 (Airflow, DBT, Kafka Connect → Slack/Email)
- 스키마 버전 관리 (버전 태깅, 선택적 소비)
- 표준화 계층(Transform Layer) 운영

---

## 7.2.8 푸시 vs 풀 vs 폴링 패턴

- 푸시 전략은 원천에서 대상으로 보내줌
- 풀 전략은 대상에서 원천 데이터를 끌어옴
- 폴링은 변경 사항이 감지되면 풀과 같이 대상에서 원천을 끌어옴

---

# 7.3 배치 수집 고려 사항
- 시간 간격 배치 수집 : 일반적인 방법 (airflow 등). 야간에 데이터 한번에 처리 등
- 크기 기반 배치 수집 : IoT 데이터와 같은 실시간 데이터에서 주로 사용. 바이트 크기가 일정 부분 넘으면 수신 등

## 7.3.1 스냅숏 또는 차등 추출
- 전체 스냅숏시 갱신할 때마다 원천의 전체 현재 상태를 파악.
- 차등 갱신 == 증분 갱신. 마지막으로 읽은 이후의 갱신 및 변경 내용만 가져옴옴

---

## 7.3.2 파일 기반 익스포트 및 수집
- 파일 기반 익스포트는 푸시 방법. (원천 시스템에서 데이터를 밀어넣는 방식.)
- 원천 시스템에서 전처리 진행

## 7.3.3 ETL과 ELT
- Extract : 원천 시스템에서 데이터를 가져오는 것을 의미. 푸시, 풀 모두 해당됨
  - 추출시 메타데이터 읽기와 스키마 변경이 필요할 수 있음
- Load : 스토리지 대상에 적재하기. 변환 완료된 시점일 수 있고 이후 변환을 위해 적재하는 걸 수 있음.

---

## 7.3.4 입력, 갱신 및 배치 크기
- 소수 사용자가 대규모 행 변경 수행 < 다수 사용자가 소규모 행 변경 수행에 더 많은 성능 필요
  - ex. 트랜잭션 데이터베이스
- 따라서 데이터베이스, 스토어의 갱신 패턴을 알고 적절하게 사용 필요.

## 7.3.5 데이터 마이그레이션
- 기존 시스템과 새로운 시스템이 어떤 방식으로 각각 스키마를 처리하는지 알기

---

# 7.4 메시지 및 스트림 수집에 관한 고려 사항

## 7.4.1 스키마의 진화
- 스키마의 진화 해결 제안사항
  - 이벤트 처리 프레임워크에 스키마 레지스트리가 있는 경우 이를 사용해 스키마 변경 사항을 버전화.
  - 데드레터 큐를 사용해 처리되지 않은 이벤트와 관련된 문제 조사
  - 스키마 변경에 관해 업스트림 이해관계자와 지속적으로 소통하고 변경에 능동적 대처

---

## 7.4.2 늦게 도착하는 데이터
- 인터넷 전송 지연 등의 문제 흔히 발생
- 늦게 도착하는 데이터를 처리하려면 늦게 도착하는 데이터가 더이상 처리되지 않는 컷 오프 시간을 설정해야 한다.

## 7.4.3 주문 및 복수 전달
- 메시지는 최소 한 번 이상 전달. 중복 될 수 있음을 고려

## 7.4.4 재생
- 리플레이 기능. 특정 시간 범위에 대해 데이터를 재입력 혹은 재처리 할 수 있음
- 래빗MQ는 모든 사용자가 메시지를 소비한 후 메시지를 삭제

---

## 7.4.5 유효 시간
- 최대 메시지 보존 시간
- 너무 많은 백로그는 지연시간을 늘리고 성능을 저하시킴

## 7.4.6 메시지 크기
- 최대 메시지 크기를 처리할 수 있는지 확인해야함

## 7.4.7 에러 처리와 데드레터 큐
- 이벤트 처리 실패시 데드레터를 별도 보관하여 재처리

---

## 7.4.8 소비자 풀 앤 푸시
- Pull Subscription : 풀 방식의 구독. 사용자가 토픽에서 메시지를 읽음. 소비자(Consumer)가 메시지 큐에 직접 요청(polling) 해서 새 메시지가 있는지 확인
- 푸시 구독 : 서비스가 수신자에게 메시지를 사용할 수 있도록 함. 메시지 큐 시스템이 새로운 메시지가 도착하면 자동으로 소비자(Consumer)에게 전달(HTTP POST, gRPC 등)

## 7.4.9 위치
- 데이터를 수집하는 위치와 저장하는 위치, 분석하는 위치가 다를 수 있음
- 이때 전송하는 비용을 고려할 것
- 가까울수록 대역폭, 지연시간은 빠름

---

# 7.5 데이터 수집 방법

---

# 7.6 함께 일할 담당자

---

# 7.7 드러나지 않는 요소