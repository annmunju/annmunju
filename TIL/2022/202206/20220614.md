# 20220614

- 핸즈온 머신러닝 1장
 
---

### 1. 머신러닝 시스템 종류
    1. 사람의 감독하에 훈련하는 것인지, 그렇지 않은 것인지
    2. 실시간으로 점진적인 학습을 하는지 아닌지
    3. 기존 데이터 포인트와 새 데이터 포인트를 비교 vs 훈련 데이터셋에 패턴 발견해 예측 모델 만들기
    

---

#### A. 지도학습과 비지도학습

1) 지도학습 : 훈련 세트에 레이블이 있음. (샘플값 - 레이블값) 다양한 샘플값을 훈련시켜 새로운 샘플이 있을 때 레이블 값을 도출함.

- 분류 : 범주(클래스) 찾기
- 회귀 : 값을 도출
    - 로지스틱 회귀 = 분류. 클래스에 속할 확률을 출력
    

! 지도학습 알고리즘

- k-nearest neighbors
- linear regression
- logistic regression
- support vector machine (SVM)
- decision tree → random forest
- neural networks (일부 신경망 구조는 비지도 혹은 준지도 학습일 수 있음)

2) 비지도학습 : 훈련 데이터에 레이블 없음

- 계층 군집
- 시각화, 차원축소 → 특성 추출
- 이상치 탐지, 특이치 탐지
- 연관 규칙 학습 (장바구니 분석)

! 비지도학습 알고리즘

- clustering
    - k-means
    - DBSCAN
    - hierarchical cluster analysis (HCA)
- outlier detection, novelty detection
    - one-class SVM
    - isolation forest
- visualization and dimensionality reduction
    - principal component analysis (PCA)
    - kernel PCA
    - locally-linear embedding (LLE)
    - t-distributed stochastic neighbor embedding
- association rule learning
    - Apriori
    - Eclat

3) 준지도학습 : 지도학습 + 비지도학습의 조합으로 이뤄짐. 

- 심층 신뢰 신경망 (DBN) : 여러겹으로 쌓은 제한된 볼츠만 머신(RBM)에 기초함. RBM 순차적으로 훈련된 다음 전체 시스템이 지도학습 방식으로 세밀하게 조정됨.

4) 강화학습 : 에이전트(학습 시스템)은 환경을 관찰해 행동을 실행하고 그 결과로 보상(또는 벌점)을 받음. 시간이 지나며 가장 큰 보상을 얻기위해 정책(최상의 전략)을 스스로 학습.

#### B. 배치 학습과 온라인 학습

1) 배치 학습 : 가용한 데이터를 모두 사용해 훈련 = 오프라인 학습

2) 온라인 학습 : 데이터를 순차적으로 한 개씩(또는 미니배치 단위로) 주입해서 시스템을 훈련. = 점진적 학습

- 학습률 : 데이터에 얼마나 빠르게 적응할 것인지. 학습률이 높으면 시스템이 데이터에 빨리 적응하지만 예전 데이터는 금방 잊음. 학습률이 낮으면 시스템 관성이 커져 느리게 학습됨.
- 단점 : 시스템에 나쁜 데이터 주입될때 성능 감소. 모니터링 필수.

#### C. 사례 기반 학습과 모델 기반 학습

1) 사례 기반 학습 : 유사도 측정해 훈련 샘플을 기억하며 학습하는 것.

2) 모델 기반 학습 : 샘플의 모델을 만들어 예측에 사용하는 것.

- 선형 모델 : 모델 파라미터를 조정해 선형함수를 표현하는 모델을 만듦.
    - 측정 지표 : 효용 함수(적합도 함수) / 비용 함수를 정의해 측정
    - [연습 문제](./practice/01_practice.ipynb)
    

---

### 2. 머신러닝 고려사항

1) 데이터의 양 (많아야 함)

2) 대표성이 큰 훈련 데이터 : 샘플링 잡음, 샘플링 편향 없이

3) 고품질의 데이터 (이상치, 잡음 등을 제거)

4) 특성 공학 : 훈련에 사용할 좋은 특성들 찾기 

- 특성 선택 : 가진 특성 중 훈련에 가장 유용한 특성 선택
- 특성 추출 : 특성 결합해 더 유용한 특성 만들기 (차원 축소 알고리즘 등)

5) 훈련 데이터가 과대적합(과소적합)되지 않아야 함

- 과대적합 방지를 위해 **규제** 사용. **자유도** 조정
- 규제는 하이퍼파라미터가 결정(학습 알고리즘에서 주요하게 작용하는 파라미터). 그래서 하이퍼파라미터 튜닝이 매우 중요함.

---

### 3. 모델 평가 (테스트와 검증)

- 훈련 세트와 테스트 세트를 분리 (70:30 ~ 80:20)
    - 홀드아웃 검증 (훈련세트에서 일부를 떼어내어 검증 세트 만들기)
    - 교차 검증 (작은 검증 세트를 여러개 사용해 반복적으로 검증)