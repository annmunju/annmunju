# 20221005

- AI 강좌 필기 정리

---

## review
- Underfitting, Overfitting
    - bias 가 무엇인가
    - varience 가 무엇인가
- Overfitting 해결법
    - 데이터 늘리기
    - Feature 줄이기
    - Regularization
- Regularization
    - 왜 해야하는가?
        - generalization이 안되는 경우
        - overfitting 한 경우
    - 역할
        - w의 영향을 줄임
        - bias 높여주고 varience 낮춰줌
    - 사용 방법
        - J = (y-hat - y)^2 + (lambda)*(w^2) = 감소시킬 error + 감소시킬 파라미터 w(영향이 줄어듦) -> GD를 통해서 감소시킴

---

## 수업
- y = wx+b 
    - w : 기울기. 영향이 큼
    - b : y절편. 영향이 작음 (상,하로 움직임)
- linear regression과 logistic regression의 Regularization 방식은 동일

## Tasks
- ML 강의를 통해 배운 내용 Tool box 만들기 `class LinearRegression ...`
    - linear_regression.py
    - logistic_regression.py
    - ploting 하는 함수도 만들어 두면 도움이 될 듯