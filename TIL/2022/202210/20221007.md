# 20221007

- AI 강좌 필기 정리

---

## review
- Continus vs Discript
- 0, 1 categric한 경우에 왜 LR 사용 못하는가?
    - 선형식의 경우 예측 범위의 제한이 없어서 해석에 문제가 생길 수 있음
    - 새로운 데이터가 추가되어 모델을 훈련할 때 Decision boundary가 바뀌어서 잘못된 해석을 할 수 있음
- Cost Function
    - L2 norm
- Gradant Descent
- Logistic regression
    - sigmoid function
    - prob으로 해석가능
- f(x) = P(y|x;w,b)
- Regularization (정규화)
    - overfitting (<-> underfitting)
    - weight의 영향을 줄이기 위해서 cost function에 (lambda * weight)를 같이 넣어줌
        - GD를 할 때 미분하면서 양을 통제하기 위해 lambda를 넣음

## Neuralnets
- Neural Networks
- 예시 공부
- Decesion Tree

### Neural Networks 용어 이해
1. inference (prediction) : 함수를 고정해 둔 상태에서 x를 넣어서 예측해봄
2. training : 훈련해서 적절한 함수 찾기

### 개념 이해
- f(f(x)) -> 함수 안에 또 다른 함수가 있는 경우 :activation 함수
- input feature가 여러개일 때 이를 조합해 새로운 layer로 만들어서 하나의 결과 (output)로 추출하게 됨
    - 드러나지 않은 layer는 hidden layer(activation)
- input layer -> hidden layer -> output layer
    - input, output layer를 레이어로 보지 않는 견해도 있음
- Neuralnet에서 activation은 설명하기 어려움
- 모델의 특징 전반을 이르는 말 : archtecture

### 예시
1. 사람 이미지
- 사람 이미지 픽셀을 길게 나열하면 벡터화가 됨 (Input)
- hidden layer을 통해 output 추출
    - layer에서 선의 특징 -> 눈/코/입 등 ... -> 얼굴 형태를 인식하게 됨
2. 자동차 이미지
- 자동차 선 특징 -> 바퀴/차체 등 ... -> 자동차 전체를 인식하게 됨